{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name: Alexis Lizardo\n",
    "# Student ID: 301318503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://stackoverflow.com/a/26912445\n",
    "\n",
    "def remove_headers(file_list):\n",
    "    pattern = r'^\"Date/Time\"'\n",
    "    pattern = re.compile(pattern)\n",
    "    path = file_list[0].rpartition('/')[0] + \"/\"\n",
    "    for file in file_list:\n",
    "        new_file = \"weather-data/\"+ file.split('/')[1]\n",
    "        with open(file,\"r\") as input:\n",
    "            with open(new_file,\"w\") as output: \n",
    "                for line in input:\n",
    "                    if pattern.match(line):\n",
    "                        output.write(line)\n",
    "                        break\n",
    "                for line in input:\n",
    "                    output.write(line)\n",
    "        #os.rename(new_file, path + new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_to_datetime(path):\n",
    "    fname = path.split('/')[1]\n",
    "    fname_no_ext = fname.split('.')[0]\n",
    "    date = fname_no_ext.split('-')[1]\n",
    "    dt = pd.to_datetime(date, unit='ns')\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_img_df(filenames):\n",
    "    N = len(filenames)\n",
    "    image_data = np.empty((N, 192*256), dtype=np.float32)\n",
    "    for i, f in enumerate(filenames):\n",
    "        img = misc.imread(f, mode= 'F', flatten=True)\n",
    "        image_data[i, ...] = img.flatten()\n",
    "    img_df = pd.DataFrame(image_data)\n",
    "    return img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_img_arr(filenames):\n",
    "    N = len(filenames)\n",
    "    image_data = np.empty((N, 192*256), dtype=np.uint8)\n",
    "    for i, f in enumerate(filenames):\n",
    "        img = misc.imread(f, flatten=True)\n",
    "        image_data[i, ...] = img.flatten()\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_data(filenames, dates):\n",
    "    N = dates.size\n",
    "    image_data = np.empty((N, 192*256), dtype=np.uint8)\n",
    "    i = int(0)\n",
    "    for f in filenames:\n",
    "        if (i >= N):\n",
    "            break\n",
    "        if (path_to_datetime(f) == dates.values[i]):\n",
    "            img = misc.imread(f, flatten=True)\n",
    "            image_data[i, ...] = img.flatten()\n",
    "            i = i + 1\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_datetime(filenames):\n",
    "    N = len(filenames)\n",
    "    images_date = np.empty(N, dtype=np.dtype('M8[ns]'))\n",
    "    for i, f in enumerate(filenames):\n",
    "        images_date[i] = path_to_datetime(f)\n",
    "    return images_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_path = 'katkam-scaled/'\n",
    "orig_weather_path = 'yvr-weather/'\n",
    "mod_weather_path = 'weather-data/'\n",
    "orig_files = glob.glob(os.path.join(orig_weather_path, \"*.csv\"))\n",
    "image_files = glob.glob(os.path.join(images_path, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean weather data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_headers(orig_files)\n",
    "mod_files = glob.glob(os.path.join(mod_weather_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weather data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://stackoverflow.com/a/36416258\n",
    "columns = ['Date/Time', 'Weather']\n",
    "df_from_each_file = (pd.read_csv(f, parse_dates=['Date/Time'], usecols=columns) for f in mod_files)\n",
    "weather_data = pd.concat(df_from_each_file, ignore_index=True)\n",
    "weather_data = weather_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dates of image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dates = img_datetime(image_files)\n",
    "dates_df = pd.DataFrame(images_dates, columns=['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data = create_img_df(image_files)\n",
    "# image_data['Date/Time'] = img_datetime(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather_data with dates_df to keep images which have weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(weather_data, dates_df, on = 'Date/Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weather_data.Weather.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#categories = ['Cloudy', 'Rain', 'Clear', 'Drizzle', 'Fog', 'Thunderstorms', 'Snow', 'Ice Pellets', 'Snow Pellets']\n",
    "#pattern = re.compile(r'\\b(?:%s)\\b' % '|'.join(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Cloudy', 'Rain', 'Clear', 'Drizzle', 'Fog', 'Snow']\n",
    "pattern = re.compile(r'\\b(?:(%s))\\b' % '|'.join(categories))\n",
    "data['Categories_ML'] = data['Weather'].str.findall(pattern)\n",
    "data['Categories'] = data['Weather'].str.extract(pattern, expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset = ['Categories', 'Categories_ML'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = img_data(image_files, data['Date/Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Date/Time', 'Weather', 'Categories', 'Categories_ML']\n",
    "X = data[data.columns.difference(cols)]\n",
    "X = image_data\n",
    "y = data['Categories']\n",
    "#y = MultiLabelBinarizer(classes=categories).fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = LabelEncoder()\n",
    "y_labels = lbl_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246, 49152)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(\n",
    "#     PCA(250),\n",
    "#     SVC(kernel='linear', C=2.0)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711743772242\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(250),\n",
    "    KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713523131673\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(250),\n",
    "    RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731316725979\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(250),\n",
    "    BaggingClassifier(n_estimators=300, n_jobs=-1)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(\n",
    "#     PCA(250),\n",
    "#     BaggingClassifier(SVC(kernel='linear', C=2.0),n_estimators=50, n_jobs=-1)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(250),\n",
    "    OneVsRestClassifier(SVC(kernel='linear', C=2.0), n_jobs=-1)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
