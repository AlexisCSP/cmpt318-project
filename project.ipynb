{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name: Alexis Lizardo\n",
    "# Student ID: 301318503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://stackoverflow.com/a/26912445\n",
    "\n",
    "def remove_headers(file_list):\n",
    "    pattern = r'^\"Date/Time\"'\n",
    "    pattern = re.compile(pattern)\n",
    "    path = file_list[0].rpartition('/')[0] + \"/\"\n",
    "    for file in file_list:\n",
    "        new_file = \"weather-data/\"+ file.split('/')[1]\n",
    "        with open(file,\"r\") as input:\n",
    "            with open(new_file,\"w\") as output: \n",
    "                for line in input:\n",
    "                    if pattern.match(line):\n",
    "                        output.write(line)\n",
    "                        break\n",
    "                for line in input:\n",
    "                    output.write(line)\n",
    "        #os.rename(new_file, path + new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_to_datetime(path):\n",
    "    fname = path.split('/')[1]\n",
    "    fname_no_ext = fname.split('.')[0]\n",
    "    date = fname_no_ext.split('-')[1]\n",
    "    dt = pd.to_datetime(date)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_img_df(filenames):\n",
    "    N = len(filenames)\n",
    "    image_data = np.empty((N, 192*256), dtype=np.uint8)\n",
    "    for i, f in enumerate(filenames):\n",
    "        img = misc.imread(f, flatten=True)\n",
    "        image_data[i, ...] = img.flatten()\n",
    "    img_df = pd.DataFrame(image_data)\n",
    "    return img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_dt(filenames):\n",
    "    N = len(filenames)\n",
    "    images_date = np.empty(N, dtype=np.dtype('M8[ns]'))\n",
    "    for i, f in enumerate(filenames):\n",
    "        images_date[i] = path_to_datetime(f)\n",
    "    return images_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_path = 'katkam-scaled/'\n",
    "orig_weather_path = 'yvr-weather/'\n",
    "mod_weather_path = 'weather-data/'\n",
    "orig_files = glob.glob(os.path.join(orig_weather_path, \"*.csv\"))\n",
    "image_files = glob.glob(os.path.join(images_path, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean weather data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_headers(orig_files)\n",
    "mod_files = glob.glob(os.path.join(mod_weather_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weather data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://stackoverflow.com/a/36416258\n",
    "columns = ['Date/Time', 'Weather']\n",
    "df_from_each_file = (pd.read_csv(f, parse_dates=['Date/Time'], usecols=columns) for f in mod_files)\n",
    "weather_data = pd.concat(df_from_each_file, ignore_index=True)\n",
    "weather_data = weather_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_data.Weather.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories = ['Cloudy', 'Rain', 'Clear', 'Drizzle', 'Fog', 'Thunderstorms', 'Snow', 'Ice Pellets', 'Snow Pellets']\n",
    "#pattern = re.compile(r'\\b(?:%s)\\b' % '|'.join(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexis/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "categories = ['Cloudy', 'Rain', 'Clear', 'Drizzle', 'Fog', 'Thunderstorms', 'Snow']\n",
    "pattern = re.compile(r'\\b(?:(%s))\\b' % '|'.join(categories))\n",
    "weather_data['Categories'] = weather_data['Weather'].str.extract(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = create_img_df(image_files)\n",
    "image_data['Date/Time'] = img_dt(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dates = img_dt(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather data with corresponding image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(weather_data, image_data, on = 'Date/Time')\n",
    "#data = weather_data[weather_data['Date/Time'] == dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Date/Time', 'Weather', 'Categories']\n",
    "X = data[data.columns.difference(cols)]\n",
    "Y = data['Categories']\n",
    "#Y = MultiLabelBinarizer(classes=categories).fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_pipeline(\n",
    "#     PCA(250),\n",
    "#     OneVsRestClassifier(SVC(kernel='linear', C=2.0))\n",
    "# )\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(250),\n",
    "    #KNeighborsClassifier(6)\n",
    "    SVC(kernel='linear', decision_function_shape='ovr')\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674377224199\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
